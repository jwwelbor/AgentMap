"""
Comprehensive test suite for dependency checker cache integration.

Tests the dependency validation cache functionality including:
- Environment change detection and cache invalidation
- Parallel dependency validation performance
- Import operation resource management
- Thread-safe dependency checking
- Cache key generation and validation

Based on critical issues identified in StorageConfigService availability cache review.
"""
import asyncio
import concurrent.futures
import importlib
import os
import platform
import subprocess
import sys
import tempfile
import threading
import time
import unittest
from pathlib import Path
from unittest.mock import patch, MagicMock, Mock
from datetime import datetime, timezone

from agentmap.services.config.dependency_availability_cache import (
    DependencyAvailabilityCache,
    DependencyValidationStrategy,
    EnvironmentTracker
)
from tests.utils.mock_service_factory import MockServiceFactory


class TestEnvironmentTracker(unittest.TestCase):
    """Test environment tracking for dependency cache invalidation."""
    
    def setUp(self):
        """Set up test fixtures."""
        self.tracker = EnvironmentTracker()
    
    def test_environment_hash_generation(self):
        """Test environment hash generation includes relevant markers."""
        hash1 = self.tracker.get_environment_hash()
        
        # Hash should be consistent on repeated calls
        hash2 = self.tracker.get_environment_hash()
        self.assertEqual(hash1, hash2)
        
        # Hash should be 16 characters (truncated SHA-256)
        self.assertEqual(len(hash1), 16)
        self.assertTrue(all(c in '0123456789abcdef' for c in hash1))
    
    def test_environment_cache_invalidation(self):
        """Test environment cache invalidation forces recomputation."""
        # Get initial hash
        hash1 = self.tracker.get_environment_hash()
        
        # Invalidate cache
        self.tracker.invalidate_environment_cache()
        
        # Next call should recompute (may be same or different)
        hash2 = self.tracker.get_environment_hash()
        self.assertEqual(len(hash2), 16)  # Should still be valid format
    
    def test_environment_hash_with_pip_failure(self):
        """Test environment hash generation when pip freeze fails."""
        with patch('subprocess.run') as mock_run:
            # Simulate pip freeze failure
            mock_run.side_effect = subprocess.CalledProcessError(1, "pip")
            
            self.tracker.invalidate_environment_cache()
            hash_result = self.tracker.get_environment_hash()
            
            # Should fallback gracefully
            self.assertEqual(len(hash_result), 16)
    
    def test_environment_hash_with_timeout(self):
        """Test environment hash generation when pip freeze times out."""
        with patch('subprocess.run') as mock_run:
            # Simulate pip freeze timeout
            mock_run.side_effect = subprocess.TimeoutExpired("pip", 10)
            
            self.tracker.invalidate_environment_cache()
            hash_result = self.tracker.get_environment_hash()
            
            # Should fallback gracefully
            self.assertEqual(len(hash_result), 16)
    
    def test_environment_hash_thread_safety(self):
        """Test environment hash computation is thread-safe."""
        hashes = []
        errors = []
        
        def get_hash_worker(worker_id: int):
            """Worker that gets environment hash."""
            try:
                for _ in range(10):
                    hash_val = self.tracker.get_environment_hash()
                    hashes.append((worker_id, hash_val))
                    time.sleep(0.001)
            except Exception as e:
                errors.append((worker_id, str(e)))
        
        # Start multiple threads
        threads = []
        for i in range(5):
            thread = threading.Thread(target=get_hash_worker, args=(i,))
            threads.append(thread)
            thread.start()
        
        for thread in threads:
            thread.join()
        
        # Verify no errors and consistent hashes
        self.assertEqual(len(errors), 0, f"Thread errors: {errors}")
        self.assertEqual(len(hashes), 50)  # 5 workers Ã— 10 iterations
        
        # All hashes should be the same (cached)
        unique_hashes = set(hash_val for _, hash_val in hashes)
        self.assertEqual(len(unique_hashes), 1, "Hash should be consistent across threads")


class TestDependencyValidationStrategy(unittest.TestCase):
    """Test dependency validation strategy functionality."""
    
    def setUp(self):
        """Set up test fixtures."""
        self.environment_tracker = EnvironmentTracker()
        self.strategy = DependencyValidationStrategy(
            dependency_name="test_deps",
            dependencies=["json", "os", "sys"],  # Built-in modules for testing
            environment_tracker=self.environment_tracker
        )
    
    def test_successful_validation(self):
        """Test successful validation of available dependencies."""
        async def run_test():
            config = {"test": "config"}
            result = await self.strategy.validate(config)
            
            self.assertTrue(result["enabled"])
            self.assertTrue(result["validation_passed"])
            self.assertIsNone(result["last_error"])
            self.assertEqual(len(result["warnings"]), 0)
            self.assertIn("validation_duration", result["performance_metrics"])
            self.assertIn("json", result["validation_results"])
            self.assertTrue(result["validation_results"]["json"])
        
        asyncio.run(run_test())
    
    def test_failed_validation(self):
        """Test validation failure with missing dependencies."""
        strategy = DependencyValidationStrategy(
            dependency_name="missing_deps",
            dependencies=["nonexistent_module_12345"],
            environment_tracker=self.environment_tracker
        )
        
        async def run_test():
            config = {"test": "config"}
            result = await strategy.validate(config)
            
            self.assertFalse(result["enabled"])
            self.assertFalse(result["validation_passed"])
            self.assertIsNotNone(result["last_error"])
            self.assertIn("nonexistent_module_12345", result["last_error"])
            self.assertIn("nonexistent_module_12345", result["validation_results"])
            self.assertFalse(result["validation_results"]["nonexistent_module_12345"])
        
        asyncio.run(run_test())
    
    def test_parallel_validation_performance(self):
        """Test parallel validation improves performance."""
        # Create strategy with multiple dependencies
        many_deps = ["json", "os", "sys", "time", "datetime", "platform"]
        strategy = DependencyValidationStrategy(
            dependency_name="many_deps",
            dependencies=many_deps,
            environment_tracker=self.environment_tracker
        )
        
        async def run_test():
            start_time = time.perf_counter()
            config = {"test": "config"}
            result = await strategy.validate(config)
            end_time = time.perf_counter()
            
            validation_duration = end_time - start_time
            
            # All deps should be valid
            self.assertTrue(result["enabled"])
            self.assertEqual(len(result["validation_results"]), len(many_deps))
            
            # Performance should indicate parallel validation
            self.assertTrue(result["performance_metrics"]["parallel_validation"])
            self.assertEqual(result["performance_metrics"]["dependencies_checked"], len(many_deps))
            
            # Validation should be reasonably fast (parallel execution)
            self.assertLess(validation_duration, 5.0)  # Should complete within 5 seconds
        
        asyncio.run(run_test())
    
    def test_validation_timeout_handling(self):
        """Test validation timeout handling."""
        strategy = DependencyValidationStrategy(
            dependency_name="timeout_test",
            dependencies=["json", "os"],
            environment_tracker=self.environment_tracker
        )
        strategy._import_timeout = 0.001  # Very short timeout to trigger timeout
        
        async def run_test():
            config = {"test": "config"}
            result = await strategy.validate(config)
            
            # Should handle timeout gracefully
            self.assertFalse(result["enabled"])
            self.assertIn("timed out", result["last_error"])
        
        asyncio.run(run_test())
    
    def test_cache_key_generation(self):
        """Test cache key generation includes environment tracking."""
        config = {"test": "config"}
        key1 = self.strategy.get_cache_key(config)
        
        # Key should be consistent
        key2 = self.strategy.get_cache_key(config)
        self.assertEqual(key1, key2)
        
        # Key should be 16 characters (truncated SHA-256)
        self.assertEqual(len(key1), 16)
        
        # Different dependencies should produce different keys
        other_strategy = DependencyValidationStrategy(
            dependency_name="other_deps",
            dependencies=["different", "modules"],
            environment_tracker=self.environment_tracker
        )
        key3 = other_strategy.get_cache_key(config)
        self.assertNotEqual(key1, key3)
    
    def test_cache_key_environment_sensitivity(self):
        """Test cache key changes when environment changes."""
        config = {"test": "config"}
        key1 = self.strategy.get_cache_key(config)
        
        # Invalidate environment cache to simulate environment change
        self.environment_tracker.invalidate_environment_cache()
        
        # Force environment hash recomputation by mocking different output
        with patch.object(self.environment_tracker, '_compute_environment_hash', 
                         return_value="different_environment_hash"):
            key2 = self.strategy.get_cache_key(config)
        
        # Keys should be different when environment changes
        self.assertNotEqual(key1, key2)
    
    def test_import_cleanup(self):
        """Test proper cleanup of imported modules."""
        original_modules = set(sys.modules.keys())
        
        # Test import cleanup with a module that might import sub-modules
        success, error, warning = self.strategy._validate_single_dependency("json")
        
        self.assertTrue(success)
        self.assertIsNone(error)
        
        # Should not have significantly altered sys.modules
        # (json is built-in so may not be cleaned up, but test the mechanism)
        final_modules = set(sys.modules.keys())
        new_modules = final_modules - original_modules
        
        # Should not have added many new modules
        self.assertLess(len(new_modules), 10)
    
    def test_versioned_dependency_validation(self):
        """Test validation of dependencies with version requirements."""
        # Test with a module that has version requirements
        strategy = DependencyValidationStrategy(
            dependency_name="versioned_deps",
            dependencies=["json>=1.0", "sys>=1.0"],  # Built-ins should pass
            environment_tracker=self.environment_tracker
        )
        
        async def run_test():
            config = {"test": "config"}
            result = await strategy.validate(config)
            
            # Should handle versioned dependencies
            self.assertIn("json", result["validation_results"])
            self.assertIn("sys", result["validation_results"])
        
        asyncio.run(run_test())
    
    def test_resource_leak_prevention(self):
        """Test prevention of resource leaks during validation."""
        import gc
        import psutil
        
        process = psutil.Process()
        initial_memory = process.memory_info().rss
        
        async def run_validation_loop():
            for i in range(100):
                config = {"iteration": i}
                result = await self.strategy.validate(config)
                self.assertTrue(result["enabled"])
                
                # Force garbage collection periodically
                if i % 20 == 0:
                    gc.collect()
        
        asyncio.run(run_validation_loop())
        
        final_memory = process.memory_info().rss
        memory_increase = final_memory - initial_memory
        memory_increase_mb = memory_increase / (1024 * 1024)
        
        # Memory increase should be minimal (<10MB)
        self.assertLess(memory_increase_mb, 10.0, 
                       f"Memory leaked {memory_increase_mb:.1f}MB during validation")


class TestDependencyAvailabilityCache(unittest.TestCase):
    """Test dependency availability cache functionality."""
    
    def setUp(self):
        """Set up test fixtures."""
        self.temp_dir = tempfile.mkdtemp()
        self.cache_file = Path(self.temp_dir) / "dependency_cache.json"
        self.cache = DependencyAvailabilityCache(str(self.cache_file))
    
    def tearDown(self):
        """Clean up test fixtures."""
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_dependency_group_registration(self):
        """Test registration of dependency groups."""
        dependencies = ["json", "os", "sys"]
        self.cache.register_dependency_group("test_group", dependencies)
        
        # Should register without errors
        self.assertIn("test_group", self.cache._registered_strategies)
        
        strategy = self.cache._registered_strategies["test_group"]
        self.assertEqual(strategy.dependency_name, "test_group")
        self.assertEqual(strategy.dependencies, dependencies)
    
    def test_dependency_availability_cache_hit(self):
        """Test dependency availability cache hit scenario."""
        dependencies = ["json", "os"]
        self.cache.register_dependency_group("cache_test", dependencies)
        
        async def run_test():
            config = {"test": "config"}
            
            # First call should generate cache
            result1 = await self.cache.get_dependency_availability("cache_test", config)
            self.assertTrue(result1["enabled"])
            
            # Second call should hit cache
            result2 = await self.cache.get_dependency_availability("cache_test", config)
            self.assertTrue(result2["enabled"])
            
            # Results should be identical (cached)
            self.assertEqual(result1["checked_at"], result2["checked_at"])
        
        asyncio.run(run_test())
    
    def test_dependency_availability_cache_miss(self):
        """Test dependency availability cache miss scenario."""
        dependencies = ["nonexistent_module_67890"]
        self.cache.register_dependency_group("miss_test", dependencies)
        
        async def run_test():
            config = {"test": "config"}
            result = await self.cache.get_dependency_availability("miss_test", config)
            
            self.assertFalse(result["enabled"])
            self.assertFalse(result["validation_passed"])
            self.assertIsNotNone(result["last_error"])
        
        asyncio.run(run_test())
    
    def test_unknown_dependency_group(self):
        """Test handling of unknown dependency groups."""
        async def run_test():
            result = await self.cache.get_dependency_availability("unknown_group")
            
            self.assertFalse(result["enabled"])
            self.assertFalse(result["validation_passed"])
            self.assertIn("Unknown dependency group", result["last_error"])
        
        asyncio.run(run_test())
    
    def test_environment_cache_invalidation(self):
        """Test environment-based cache invalidation."""
        dependencies = ["json", "os"]
        self.cache.register_dependency_group("env_test", dependencies)
        
        async def run_test():
            config = {"test": "config"}
            
            # Generate initial cache
            result1 = await self.cache.get_dependency_availability("env_test", config)
            self.assertTrue(result1["enabled"])
            
            # Invalidate environment cache
            self.cache.invalidate_environment_cache()
            
            # Next call should regenerate due to environment change
            result2 = await self.cache.get_dependency_availability("env_test", config)
            self.assertTrue(result2["enabled"])
            
            # Check times should be different (regenerated)
            self.assertNotEqual(result1["checked_at"], result2["checked_at"])
        
        asyncio.run(run_test())
    
    def test_dependency_cache_clearing(self):
        """Test clearing of dependency caches."""
        dependencies = ["json", "os"]
        self.cache.register_dependency_group("clear_test", dependencies)
        
        async def run_test():
            config = {"test": "config"}
            
            # Generate cache
            result1 = await self.cache.get_dependency_availability("clear_test", config)
            self.assertTrue(result1["enabled"])
            
            # Clear specific dependency cache
            self.cache.clear_dependency_cache("clear_test")
            
            # Next call should regenerate
            result2 = await self.cache.get_dependency_availability("clear_test", config)
            self.assertTrue(result2["enabled"])
            
            # Check times should be different
            self.assertNotEqual(result1["checked_at"], result2["checked_at"])
        
        asyncio.run(run_test())
    
    def test_cache_stats_reporting(self):
        """Test cache statistics reporting."""
        # Test with empty cache
        stats = self.cache.get_cache_stats()
        self.assertFalse(stats["cache_exists"])
        self.assertEqual(stats["total_dependencies"], 0)
        
        # Register and use dependency
        dependencies = ["json", "os"]
        self.cache.register_dependency_group("stats_test", dependencies)
        
        async def run_test():
            config = {"test": "config"}
            await self.cache.get_dependency_availability("stats_test", config)
            
            # Check stats after cache generation
            stats = self.cache.get_cache_stats()
            self.assertTrue(stats["cache_exists"])
            self.assertGreater(stats["total_dependencies"], 0)
            self.assertIn("dependency.stats_test", stats["dependency_groups"])
            self.assertIn("environment_hash", stats)
        
        asyncio.run(run_test())
    
    def test_concurrent_dependency_validation(self):
        """Test concurrent dependency validation across multiple groups."""
        # Register multiple dependency groups
        groups = {
            "group1": ["json", "os"],
            "group2": ["sys", "time"],
            "group3": ["platform", "datetime"]
        }
        
        for name, deps in groups.items():
            self.cache.register_dependency_group(name, deps)
        
        async def validate_group(group_name):
            """Validate a single dependency group."""
            config = {"test": "config"}
            return await self.cache.get_dependency_availability(group_name, config)
        
        async def run_test():
            # Validate all groups concurrently
            tasks = [validate_group(name) for name in groups.keys()]
            results = await asyncio.gather(*tasks)
            
            # All should succeed
            for result in results:
                self.assertTrue(result["enabled"])
                self.assertTrue(result["validation_passed"])
        
        asyncio.run(run_test())
    
    def test_thread_safety_dependency_cache(self):
        """Test thread safety of dependency cache operations."""
        dependencies = ["json", "os", "sys"]
        self.cache.register_dependency_group("thread_test", dependencies)
        
        results = []
        errors = []
        
        def worker_thread(thread_id: int):
            """Worker thread for concurrent dependency validation."""
            try:
                async def validate():
                    config = {"thread_id": thread_id}
                    result = await self.cache.get_dependency_availability("thread_test", config)
                    return result
                
                # Each thread runs its own event loop
                result = asyncio.run(validate())
                results.append((thread_id, result["enabled"]))
                
            except Exception as e:
                errors.append((thread_id, str(e)))
        
        # Start multiple concurrent threads
        threads = []
        for i in range(5):
            thread = threading.Thread(target=worker_thread, args=(i,))
            threads.append(thread)
            thread.start()
        
        # Wait for all threads to complete
        for thread in threads:
            thread.join()
        
        # Verify no errors and all validations succeeded
        self.assertEqual(len(errors), 0, f"Thread safety errors: {errors}")
        self.assertEqual(len(results), 5)
        for thread_id, enabled in results:
            self.assertTrue(enabled, f"Thread {thread_id} validation failed")
    
    def test_cache_corruption_recovery(self):
        """Test recovery from cache file corruption."""
        dependencies = ["json", "os"]
        self.cache.register_dependency_group("corruption_test", dependencies)
        
        async def run_test():
            config = {"test": "config"}
            
            # Generate initial cache
            result1 = await self.cache.get_dependency_availability("corruption_test", config)
            self.assertTrue(result1["enabled"])
            
            # Corrupt cache file
            with open(self.cache_file, 'w') as f:
                f.write("corrupted json content")
            
            # Next call should recover gracefully
            result2 = await self.cache.get_dependency_availability("corruption_test", config)
            self.assertTrue(result2["enabled"])
            
            # Cache should be regenerated
            self.assertNotEqual(result1["checked_at"], result2["checked_at"])
        
        asyncio.run(run_test())
    
    def test_cache_performance_regression(self):
        """Test cache performance meets targets."""
        dependencies = ["json", "os", "sys", "time"]
        self.cache.register_dependency_group("perf_test", dependencies)
        
        async def run_test():
            config = {"test": "config"}
            
            # Generate cache
            await self.cache.get_dependency_availability("perf_test", config)
            
            # Measure cache hit performance
            hit_times = []
            for _ in range(50):
                start_time = time.perf_counter()
                result = await self.cache.get_dependency_availability("perf_test", config)
                end_time = time.perf_counter()
                
                hit_times.append((end_time - start_time) * 1000)  # ms
                self.assertTrue(result["enabled"])
            
            avg_hit_time = sum(hit_times) / len(hit_times)
            max_hit_time = max(hit_times)
            
            # Performance targets from architectural review
            self.assertLess(avg_hit_time, 1.0, f"Avg cache hit {avg_hit_time:.3f}ms exceeds 1ms target")
            self.assertLess(max_hit_time, 5.0, f"Max cache hit {max_hit_time:.3f}ms exceeds 5ms threshold")
        
        asyncio.run(run_test())


class TestDependencyCheckerCacheIntegration(unittest.TestCase):
    """Test integration with DependencyCheckerService patterns."""
    
    def setUp(self):
        """Set up test fixtures."""
        self.temp_dir = tempfile.mkdtemp()
        self.cache_file = Path(self.temp_dir) / "integration_cache.json"
        self.cache = DependencyAvailabilityCache(str(self.cache_file))
        
        # Register common dependency groups
        self.cache.register_dependency_group("llm_openai", ["openai", "tiktoken"])
        self.cache.register_dependency_group("llm_anthropic", ["anthropic"])
        self.cache.register_dependency_group("storage_vector", ["chromadb", "sentence_transformers"])
        self.cache.register_dependency_group("storage_csv", ["pandas", "numpy"])
    
    def tearDown(self):
        """Clean up test fixtures."""
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_llm_dependency_integration(self):
        """Test LLM dependency validation integration."""
        async def run_test():
            # Test OpenAI dependencies (likely missing in test environment)
            openai_result = await self.cache.get_dependency_availability("llm_openai")
            self.assertIn("enabled", openai_result)
            self.assertIn("validation_passed", openai_result)
            
            # Test Anthropic dependencies (likely missing in test environment)
            anthropic_result = await self.cache.get_dependency_availability("llm_anthropic")
            self.assertIn("enabled", anthropic_result)
            self.assertIn("validation_passed", anthropic_result)
        
        asyncio.run(run_test())
    
    def test_storage_dependency_integration(self):
        """Test storage dependency validation integration."""
        async def run_test():
            # Test vector storage dependencies
            vector_result = await self.cache.get_dependency_availability("storage_vector")
            self.assertIn("enabled", vector_result)
            self.assertIn("last_error", vector_result)
            
            # Test CSV storage dependencies
            csv_result = await self.cache.get_dependency_availability("storage_csv")
            self.assertIn("enabled", csv_result)
            self.assertIn("last_error", csv_result)
        
        asyncio.run(run_test())
    
    def test_cross_service_cache_coordination(self):
        """Test cache coordination across multiple service types."""
        async def run_test():
            # Validate all dependency groups concurrently
            tasks = [
                self.cache.get_dependency_availability("llm_openai"),
                self.cache.get_dependency_availability("llm_anthropic"),
                self.cache.get_dependency_availability("storage_vector"),
                self.cache.get_dependency_availability("storage_csv")
            ]
            
            results = await asyncio.gather(*tasks)
            
            # All should complete without errors
            for result in results:
                self.assertIsInstance(result, dict)
                self.assertIn("enabled", result)
                self.assertIn("checked_at", result)
        
        asyncio.run(run_test())
    
    def test_service_lifecycle_management(self):
        """Test dependency cache throughout service lifecycle."""
        async def run_test():
            # Initial validation
            result1 = await self.cache.get_dependency_availability("llm_openai")
            initial_time = result1["checked_at"]
            
            # Environment change simulation
            self.cache.invalidate_environment_cache()
            
            # Re-validation after environment change
            result2 = await self.cache.get_dependency_availability("llm_openai")
            updated_time = result2["checked_at"]
            
            # Should have regenerated
            self.assertNotEqual(initial_time, updated_time)
            
            # Cache stats should reflect changes
            stats = self.cache.get_cache_stats()
            self.assertTrue(stats["cache_exists"])
            self.assertIn("environment_hash", stats)
        
        asyncio.run(run_test())


if __name__ == "__main__":
    unittest.main()
