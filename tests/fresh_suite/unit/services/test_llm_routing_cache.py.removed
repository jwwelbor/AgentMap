"""
Comprehensive test suite for LLM routing cache integration.

Tests the LLM provider availability cache functionality including:
- Network connectivity validation and retry logic
- API endpoint health checking with timeouts
- Provider-specific configuration validation
- Thread-safe LLM routing decisions
- Cache invalidation on configuration changes

Based on critical issues identified in StorageConfigService availability cache review.
"""
import asyncio
import concurrent.futures
import json
import tempfile
import threading
import time
import unittest
from pathlib import Path
from unittest.mock import patch, MagicMock, Mock, AsyncMock
from datetime import datetime, timezone

import httpx

from agentmap.services.config.llm_availability_cache import (
    LLMAvailabilityCache,
    LLMProviderValidationStrategy
)
from tests.utils.mock_service_factory import MockServiceFactory


class TestNetworkConnectivityChecker(unittest.TestCase):
    """Test network connectivity checking for LLM providers."""
    
    def setUp(self):
        """Set up test fixtures."""
        self.checker = NetworkConnectivityChecker()
        self.test_config = {
            "anthropic": {
                "api_key": "test_key",
                "base_url": "https://api.anthropic.com"
            },
            "openai": {
                "api_key": "test_key", 
                "base_url": "https://api.openai.com"
            }
        }
    
    def test_connectivity_check_initialization(self):
        """Test connectivity checker initialization."""
        self.assertEqual(self.checker._default_timeout, 30.0)
        self.assertEqual(self.checker._max_retries, 3)
        self.assertEqual(self.checker._base_backoff_delay, 1.0)
    
    @patch('httpx.AsyncClient')
    def test_successful_connectivity_check(self, mock_client_class):
        """Test successful API connectivity check."""
        # Mock successful HTTP response
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.headers = {"content-type": "application/json"}
        mock_response.json.return_value = {"status": "ok"}
        
        mock_client = AsyncMock()
        mock_client.get.return_value = mock_response
        mock_client_class.return_value.__aenter__.return_value = mock_client
        
        async def run_test():
            result = await self.checker.check_api_connectivity(
                "https://api.anthropic.com/health",
                {"Authorization": "Bearer test_key"}
            )
            
            self.assertTrue(result["connected"])
            self.assertIsNone(result["error"])
            self.assertIn("response_time_ms", result)
            self.assertGreater(result["response_time_ms"], 0)
        
        asyncio.run(run_test())
    
    @patch('httpx.AsyncClient')
    def test_connectivity_check_timeout(self, mock_client_class):
        """Test connectivity check timeout handling."""
        # Mock timeout exception
        mock_client = AsyncMock()
        mock_client.get.side_effect = httpx.TimeoutException("Request timed out")
        mock_client_class.return_value.__aenter__.return_value = mock_client
        
        async def run_test():
            result = await self.checker.check_api_connectivity(
                "https://api.anthropic.com/health",
                {"Authorization": "Bearer test_key"},
                timeout=1.0
            )
            
            self.assertFalse(result["connected"])
            self.assertIn("timed out", result["error"])
            self.assertEqual(result["response_time_ms"], 0)
        
        asyncio.run(run_test())
    
    @patch('httpx.AsyncClient')
    def test_connectivity_check_http_error(self, mock_client_class):
        """Test connectivity check HTTP error handling."""
        # Mock HTTP error response
        mock_response = Mock()
        mock_response.status_code = 503
        mock_response.headers = {"content-type": "application/json"}
        mock_response.text = "Service Unavailable"
        
        mock_client = AsyncMock()
        mock_client.get.return_value = mock_response
        mock_client_class.return_value.__aenter__.return_value = mock_client
        
        async def run_test():
            result = await self.checker.check_api_connectivity(
                "https://api.anthropic.com/health",
                {"Authorization": "Bearer test_key"}
            )
            
            self.assertFalse(result["connected"])
            self.assertIn("503", result["error"])
            self.assertIn("response_time_ms", result)
        
        asyncio.run(run_test())
    
    @patch('httpx.AsyncClient')
    def test_connectivity_check_retry_logic(self, mock_client_class):
        """Test retry logic with exponential backoff."""
        # Mock client that fails twice then succeeds
        call_count = 0
        
        async def mock_get(*args, **kwargs):
            nonlocal call_count
            call_count += 1
            if call_count < 3:
                raise httpx.ConnectError("Connection failed")
            
            mock_response = Mock()
            mock_response.status_code = 200
            mock_response.headers = {"content-type": "application/json"}
            mock_response.json.return_value = {"status": "ok"}
            return mock_response
        
        mock_client = AsyncMock()
        mock_client.get.side_effect = mock_get
        mock_client_class.return_value.__aenter__.return_value = mock_client
        
        async def run_test():
            checker = NetworkConnectivityChecker()
            checker._max_retries = 3
            checker._base_backoff_delay = 0.01  # Fast for testing
            
            result = await checker.check_api_connectivity(
                "https://api.anthropic.com/health",
                {"Authorization": "Bearer test_key"}
            )
            
            self.assertTrue(result["connected"])
            self.assertEqual(call_count, 3)  # Should have retried
        
        asyncio.run(run_test())
    
    def test_get_health_endpoint_urls(self):
        """Test health endpoint URL generation."""
        urls = self.checker.get_health_endpoint_urls("anthropic", self.test_config["anthropic"])
        
        self.assertIsInstance(urls, list)
        self.assertGreater(len(urls), 0)
        
        # Should contain valid URLs
        for url in urls:
            self.assertTrue(url.startswith("https://"))
    
    def test_network_environment_hash(self):
        """Test network environment hash generation."""
        hash1 = self.checker.get_network_environment_hash()
        hash2 = self.checker.get_network_environment_hash()
        
        # Should be consistent
        self.assertEqual(hash1, hash2)
        self.assertEqual(len(hash1), 16)
        self.assertTrue(all(c in '0123456789abcdef' for c in hash1))


class TestLLMProviderValidationStrategy(unittest.TestCase):
    """Test LLM provider validation strategy functionality."""
    
    def setUp(self):
        """Set up test fixtures."""
        self.provider_config = {
            "api_key": "test_anthropic_key",
            "base_url": "https://api.anthropic.com",
            "model": "claude-3-sonnet-20240229",
            "max_tokens": 4000
        }
        self.strategy = LLMProviderValidationStrategy("anthropic", self.provider_config)
    
    @patch('agentmap.services.config.llm_availability_cache.NetworkConnectivityChecker')
    def test_successful_validation(self, mock_checker_class):
        """Test successful LLM provider validation."""
        # Mock successful connectivity check
        mock_checker = Mock()
        mock_checker.check_api_connectivity.return_value = asyncio.Future()
        mock_checker.check_api_connectivity.return_value.set_result({
            "connected": True,
            "error": None,
            "response_time_ms": 150.5
        })
        mock_checker_class.return_value = mock_checker
        
        async def run_test():
            config = {"test": "config"}
            result = await self.strategy.validate(config)
            
            self.assertTrue(result["enabled"])
            self.assertTrue(result["validation_passed"])
            self.assertIsNone(result["last_error"])
            self.assertEqual(len(result["warnings"]), 0)
            self.assertIn("validation_duration", result["performance_metrics"])
            self.assertIn("anthropic", result["validation_results"])
        
        asyncio.run(run_test())
    
    @patch('agentmap.services.config.llm_availability_cache.NetworkConnectivityChecker')
    def test_failed_validation(self, mock_checker_class):
        """Test failed LLM provider validation."""
        # Mock failed connectivity check
        mock_checker = Mock()
        mock_checker.check_api_connectivity.return_value = asyncio.Future()
        mock_checker.check_api_connectivity.return_value.set_result({
            "connected": False,
            "error": "Connection timeout",
            "response_time_ms": 0
        })
        mock_checker_class.return_value = mock_checker
        
        async def run_test():
            config = {"test": "config"}
            result = await self.strategy.validate(config)
            
            self.assertFalse(result["enabled"])
            self.assertFalse(result["validation_passed"])
            self.assertIn("Connection timeout", result["last_error"])
        
        asyncio.run(run_test())
    
    def test_configuration_validation(self):
        """Test provider configuration validation."""
        # Test valid configuration
        valid_config = {
            "api_key": "test_key",
            "base_url": "https://api.anthropic.com",
            "model": "claude-3-sonnet-20240229"
        }
        result = self.strategy._validate_configuration(valid_config)
        self.assertTrue(result["valid"])
        self.assertEqual(len(result["errors"]), 0)
        
        # Test invalid configuration (missing api_key)
        invalid_config = {
            "base_url": "https://api.anthropic.com",
            "model": "claude-3-sonnet-20240229"
        }
        result = self.strategy._validate_configuration(invalid_config)
        self.assertFalse(result["valid"])
        self.assertGreater(len(result["errors"]), 0)
    
    def test_cache_key_generation(self):
        """Test cache key generation for LLM providers."""
        config = {"test": "config"}
        key1 = self.strategy.get_cache_key(config)
        
        # Key should be consistent
        key2 = self.strategy.get_cache_key(config)
        self.assertEqual(key1, key2)
        
        # Key should be 16 characters (truncated SHA-256)
        self.assertEqual(len(key1), 16)
        
        # Different provider configs should produce different keys
        other_strategy = LLMProviderValidationStrategy("openai", {"api_key": "different_key"})
        key3 = other_strategy.get_cache_key(config)
        self.assertNotEqual(key1, key3)
    
    def test_api_key_validation(self):
        """Test API key validation logic."""
        # Valid API key
        valid_result = self.strategy._validate_api_key("sk-1234567890abcdef")
        self.assertTrue(valid_result["valid"])
        
        # Invalid API key (too short)
        invalid_result = self.strategy._validate_api_key("short")
        self.assertFalse(invalid_result["valid"])
        
        # Missing API key
        missing_result = self.strategy._validate_api_key(None)
        self.assertFalse(missing_result["valid"])
    
    def test_model_availability_check(self):
        """Test model availability checking."""
        # Standard model should be available
        available_result = self.strategy._check_model_availability("claude-3-sonnet-20240229")
        self.assertTrue(available_result["available"])
        
        # Unknown model should be flagged
        unknown_result = self.strategy._check_model_availability("unknown-model-xyz")
        self.assertFalse(unknown_result["available"])
    
    @patch('agentmap.services.config.llm_availability_cache.NetworkConnectivityChecker')
    def test_validation_timeout_handling(self, mock_checker_class):
        """Test validation timeout handling."""
        # Mock checker that times out
        async def timeout_check(*args, **kwargs):
            await asyncio.sleep(0.1)
            raise asyncio.TimeoutError("Validation timed out")
        
        mock_checker = Mock()
        mock_checker.check_api_connectivity.side_effect = timeout_check
        mock_checker_class.return_value = mock_checker
        
        strategy = LLMProviderValidationStrategy("anthropic", self.provider_config)
        strategy._validation_timeout = 0.05  # Very short timeout
        
        async def run_test():
            config = {"test": "config"}
            result = await strategy.validate(config)
            
            self.assertFalse(result["enabled"])
            self.assertIn("timed out", result["last_error"])
        
        asyncio.run(run_test())


class TestLLMAvailabilityCache(unittest.TestCase):
    """Test LLM availability cache functionality."""
    
    def setUp(self):
        """Set up test fixtures."""
        self.temp_dir = tempfile.mkdtemp()
        self.cache_file = Path(self.temp_dir) / "llm_cache.json"
        self.cache = LLMAvailabilityCache(str(self.cache_file))
    
    def tearDown(self):
        """Clean up test fixtures."""
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_llm_provider_registration(self):
        """Test registration of LLM providers."""
        provider_config = {
            "api_key": "test_key",
            "base_url": "https://api.anthropic.com"
        }
        self.cache.register_llm_provider("anthropic", provider_config)
        
        # Should register without errors
        self.assertIn("anthropic", self.cache._registered_strategies)
        
        strategy = self.cache._registered_strategies["anthropic"]
        self.assertEqual(strategy.provider_name, "anthropic")
        self.assertEqual(strategy.provider_config, provider_config)
    
    @patch('agentmap.services.config.llm_availability_cache.NetworkConnectivityChecker')
    def test_llm_availability_cache_hit(self, mock_checker_class):
        """Test LLM availability cache hit scenario."""
        # Mock successful connectivity
        mock_checker = Mock()
        mock_checker.check_api_connectivity.return_value = asyncio.Future()
        mock_checker.check_api_connectivity.return_value.set_result({
            "connected": True,
            "error": None,
            "response_time_ms": 100.0
        })
        mock_checker_class.return_value = mock_checker
        
        provider_config = {"api_key": "test_key", "base_url": "https://api.anthropic.com"}
        self.cache.register_llm_provider("anthropic", provider_config)
        
        async def run_test():
            config = {"test": "config"}
            
            # First call should generate cache
            result1 = await self.cache.get_llm_availability("anthropic", config)
            self.assertTrue(result1["enabled"])
            
            # Second call should hit cache
            result2 = await self.cache.get_llm_availability("anthropic", config)
            self.assertTrue(result2["enabled"])
            
            # Results should be identical (cached)
            self.assertEqual(result1["checked_at"], result2["checked_at"])
        
        asyncio.run(run_test())
    
    @patch('agentmap.services.config.llm_availability_cache.NetworkConnectivityChecker')
    def test_llm_availability_cache_miss(self, mock_checker_class):
        """Test LLM availability cache miss scenario."""
        # Mock failed connectivity
        mock_checker = Mock()
        mock_checker.check_api_connectivity.return_value = asyncio.Future()
        mock_checker.check_api_connectivity.return_value.set_result({
            "connected": False,
            "error": "API key invalid",
            "response_time_ms": 0
        })
        mock_checker_class.return_value = mock_checker
        
        provider_config = {"api_key": "invalid_key"}
        self.cache.register_llm_provider("anthropic", provider_config)
        
        async def run_test():
            config = {"test": "config"}
            result = await self.cache.get_llm_availability("anthropic", config)
            
            self.assertFalse(result["enabled"])
            self.assertFalse(result["validation_passed"])
            self.assertIn("API key invalid", result["last_error"])
        
        asyncio.run(run_test())
    
    def test_unknown_llm_provider(self):
        """Test handling of unknown LLM providers."""
        async def run_test():
            result = await self.cache.get_llm_availability("unknown_provider")
            
            self.assertFalse(result["enabled"])
            self.assertFalse(result["validation_passed"])
            self.assertIn("Unknown LLM provider", result["last_error"])
        
        asyncio.run(run_test())
    
    def test_network_configuration_change_invalidation(self):
        """Test cache invalidation on network configuration changes."""
        provider_config = {"api_key": "test_key", "base_url": "https://api.anthropic.com"}
        self.cache.register_llm_provider("anthropic", provider_config)
        
        with patch('agentmap.services.config.llm_availability_cache.NetworkConnectivityChecker') as mock_checker_class:
            # Mock successful connectivity
            mock_checker = Mock()
            mock_checker.check_api_connectivity.return_value = asyncio.Future()
            mock_checker.check_api_connectivity.return_value.set_result({
                "connected": True,
                "error": None,
                "response_time_ms": 100.0
            })
            mock_checker_class.return_value = mock_checker
            
            async def run_test():
                config = {"test": "config"}
                
                # Generate initial cache
                result1 = await self.cache.get_llm_availability("anthropic", config)
                self.assertTrue(result1["enabled"])
                
                # Simulate network configuration change
                self.cache.invalidate_network_cache()
                
                # Next call should regenerate due to network change
                result2 = await self.cache.get_llm_availability("anthropic", config)
                self.assertTrue(result2["enabled"])
                
                # Check times should be different (regenerated)
                self.assertNotEqual(result1["checked_at"], result2["checked_at"])
            
            asyncio.run(run_test())
    
    def test_llm_cache_clearing(self):
        """Test clearing of LLM provider caches."""
        provider_config = {"api_key": "test_key"}
        self.cache.register_llm_provider("anthropic", provider_config)
        
        with patch('agentmap.services.config.llm_availability_cache.NetworkConnectivityChecker') as mock_checker_class:
            # Mock successful connectivity
            mock_checker = Mock()
            mock_checker.check_api_connectivity.return_value = asyncio.Future()
            mock_checker.check_api_connectivity.return_value.set_result({
                "connected": True,
                "error": None,
                "response_time_ms": 100.0
            })
            mock_checker_class.return_value = mock_checker
            
            async def run_test():
                config = {"test": "config"}
                
                # Generate cache
                result1 = await self.cache.get_llm_availability("anthropic", config)
                self.assertTrue(result1["enabled"])
                
                # Clear specific LLM cache
                self.cache.clear_llm_cache("anthropic")
                
                # Next call should regenerate
                result2 = await self.cache.get_llm_availability("anthropic", config)
                self.assertTrue(result2["enabled"])
                
                # Check times should be different
                self.assertNotEqual(result1["checked_at"], result2["checked_at"])
            
            asyncio.run(run_test())
    
    def test_concurrent_llm_validation(self):
        """Test concurrent LLM validation across multiple providers."""
        # Register multiple LLM providers
        providers = {
            "anthropic": {"api_key": "test_anthropic_key"},
            "openai": {"api_key": "test_openai_key"},
            "google": {"api_key": "test_google_key"}
        }
        
        for name, config in providers.items():
            self.cache.register_llm_provider(name, config)
        
        with patch('agentmap.services.config.llm_availability_cache.NetworkConnectivityChecker') as mock_checker_class:
            # Mock successful connectivity for all
            mock_checker = Mock()
            mock_checker.check_api_connectivity.return_value = asyncio.Future()
            mock_checker.check_api_connectivity.return_value.set_result({
                "connected": True,
                "error": None,
                "response_time_ms": 100.0
            })
            mock_checker_class.return_value = mock_checker
            
            async def validate_provider(provider_name):
                """Validate a single LLM provider."""
                config = {"test": "config"}
                return await self.cache.get_llm_availability(provider_name, config)
            
            async def run_test():
                # Validate all providers concurrently
                tasks = [validate_provider(name) for name in providers.keys()]
                results = await asyncio.gather(*tasks)
                
                # All should succeed
                for result in results:
                    self.assertTrue(result["enabled"])
                    self.assertTrue(result["validation_passed"])
            
            asyncio.run(run_test())
    
    def test_thread_safety_llm_cache(self):
        """Test thread safety of LLM cache operations."""
        provider_config = {"api_key": "test_key"}
        self.cache.register_llm_provider("anthropic", provider_config)
        
        with patch('agentmap.services.config.llm_availability_cache.NetworkConnectivityChecker') as mock_checker_class:
            # Mock successful connectivity
            mock_checker = Mock()
            mock_checker.check_api_connectivity.return_value = asyncio.Future()
            mock_checker.check_api_connectivity.return_value.set_result({
                "connected": True,
                "error": None,
                "response_time_ms": 100.0
            })
            mock_checker_class.return_value = mock_checker
            
            results = []
            errors = []
            
            def worker_thread(thread_id: int):
                """Worker thread for concurrent LLM validation."""
                try:
                    async def validate():
                        config = {"thread_id": thread_id}
                        result = await self.cache.get_llm_availability("anthropic", config)
                        return result
                    
                    # Each thread runs its own event loop
                    result = asyncio.run(validate())
                    results.append((thread_id, result["enabled"]))
                    
                except Exception as e:
                    errors.append((thread_id, str(e)))
            
            # Start multiple concurrent threads
            threads = []
            for i in range(5):
                thread = threading.Thread(target=worker_thread, args=(i,))
                threads.append(thread)
                thread.start()
            
            # Wait for all threads to complete
            for thread in threads:
                thread.join()
            
            # Verify no errors and all validations succeeded
            self.assertEqual(len(errors), 0, f"Thread safety errors: {errors}")
            self.assertEqual(len(results), 5)
            for thread_id, enabled in results:
                self.assertTrue(enabled, f"Thread {thread_id} validation failed")
    
    def test_cache_performance_regression(self):
        """Test LLM cache performance meets targets."""
        provider_config = {"api_key": "test_key"}
        self.cache.register_llm_provider("anthropic", provider_config)
        
        with patch('agentmap.services.config.llm_availability_cache.NetworkConnectivityChecker') as mock_checker_class:
            # Mock fast connectivity check
            mock_checker = Mock()
            mock_checker.check_api_connectivity.return_value = asyncio.Future()
            mock_checker.check_api_connectivity.return_value.set_result({
                "connected": True,
                "error": None,
                "response_time_ms": 50.0
            })
            mock_checker_class.return_value = mock_checker
            
            async def run_test():
                config = {"test": "config"}
                
                # Generate cache
                await self.cache.get_llm_availability("anthropic", config)
                
                # Measure cache hit performance
                hit_times = []
                for _ in range(50):
                    start_time = time.perf_counter()
                    result = await self.cache.get_llm_availability("anthropic", config)
                    end_time = time.perf_counter()
                    
                    hit_times.append((end_time - start_time) * 1000)  # ms
                    self.assertTrue(result["enabled"])
                
                avg_hit_time = sum(hit_times) / len(hit_times)
                max_hit_time = max(hit_times)
                
                # Performance targets from architectural review
                self.assertLess(avg_hit_time, 1.0, f"Avg cache hit {avg_hit_time:.3f}ms exceeds 1ms target")
                self.assertLess(max_hit_time, 5.0, f"Max cache hit {max_hit_time:.3f}ms exceeds 5ms threshold")
            
            asyncio.run(run_test())


class TestLLMRoutingCacheIntegration(unittest.TestCase):
    """Test integration with LLM routing service patterns."""
    
    def setUp(self):
        """Set up test fixtures."""
        self.temp_dir = tempfile.mkdtemp()
        self.cache_file = Path(self.temp_dir) / "routing_cache.json"
        self.cache = LLMAvailabilityCache(str(self.cache_file))
        
        # Register common LLM providers
        self.cache.register_llm_provider("anthropic", {
            "api_key": "test_anthropic_key",
            "base_url": "https://api.anthropic.com"
        })
        self.cache.register_llm_provider("openai", {
            "api_key": "test_openai_key", 
            "base_url": "https://api.openai.com"
        })
        self.cache.register_llm_provider("google", {
            "api_key": "test_google_key",
            "base_url": "https://generativelanguage.googleapis.com"
        })
    
    def tearDown(self):
        """Clean up test fixtures."""
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_llm_routing_decision_caching(self):
        """Test LLM routing decision caching integration."""
        with patch('agentmap.services.config.llm_availability_cache.NetworkConnectivityChecker') as mock_checker_class:
            # Mock connectivity - Anthropic available, OpenAI unavailable
            def mock_connectivity_check(url, *args, **kwargs):
                future = asyncio.Future()
                if "anthropic" in url:
                    future.set_result({"connected": True, "error": None, "response_time_ms": 100.0})
                else:
                    future.set_result({"connected": False, "error": "Timeout", "response_time_ms": 0})
                return future
            
            mock_checker = Mock()
            mock_checker.check_api_connectivity.side_effect = mock_connectivity_check
            mock_checker_class.return_value = mock_checker
            
            async def run_test():
                config = {"routing": {"fallback_enabled": True}}
                
                # Check all providers
                anthropic_result = await self.cache.get_llm_availability("anthropic", config)
                openai_result = await self.cache.get_llm_availability("openai", config)
                google_result = await self.cache.get_llm_availability("google", config)
                
                # Anthropic should be available, others not
                self.assertTrue(anthropic_result["enabled"])
                self.assertFalse(openai_result["enabled"])
                self.assertFalse(google_result["enabled"])
                
                # Routing logic would select Anthropic as the available provider
                available_providers = [
                    name for name, result in [
                        ("anthropic", anthropic_result),
                        ("openai", openai_result), 
                        ("google", google_result)
                    ] if result["enabled"]
                ]
                
                self.assertEqual(available_providers, ["anthropic"])
            
            asyncio.run(run_test())
    
    def test_provider_failover_caching(self):
        """Test provider failover scenario with caching."""
        with patch('agentmap.services.config.llm_availability_cache.NetworkConnectivityChecker') as mock_checker_class:
            call_count = 0
            
            def mock_connectivity_check(url, *args, **kwargs):
                nonlocal call_count
                call_count += 1
                future = asyncio.Future()
                
                # First few calls: all providers fail
                if call_count <= 3:
                    future.set_result({"connected": False, "error": "Service unavailable", "response_time_ms": 0})
                # Later calls: Anthropic comes back online
                elif "anthropic" in url:
                    future.set_result({"connected": True, "error": None, "response_time_ms": 120.0})
                else:
                    future.set_result({"connected": False, "error": "Still down", "response_time_ms": 0})
                
                return future
            
            mock_checker = Mock()
            mock_checker.check_api_connectivity.side_effect = mock_connectivity_check
            mock_checker_class.return_value = mock_checker
            
            async def run_test():
                config = {"failover": {"enabled": True}}
                
                # Initial check - all should fail
                initial_results = await asyncio.gather(
                    self.cache.get_llm_availability("anthropic", config),
                    self.cache.get_llm_availability("openai", config),
                    self.cache.get_llm_availability("google", config)
                )
                
                for result in initial_results:
                    self.assertFalse(result["enabled"])
                
                # Clear cache to simulate retry after failure
                self.cache.clear_llm_cache()
                
                # Retry check - Anthropic should now be available
                retry_results = await asyncio.gather(
                    self.cache.get_llm_availability("anthropic", config),
                    self.cache.get_llm_availability("openai", config),
                    self.cache.get_llm_availability("google", config)
                )
                
                # Anthropic should be available now
                self.assertTrue(retry_results[0]["enabled"])
                self.assertFalse(retry_results[1]["enabled"])
                self.assertFalse(retry_results[2]["enabled"])
            
            asyncio.run(run_test())
    
    def test_service_lifecycle_management(self):
        """Test LLM cache throughout service lifecycle."""
        with patch('agentmap.services.config.llm_availability_cache.NetworkConnectivityChecker') as mock_checker_class:
            # Mock successful connectivity
            mock_checker = Mock()
            mock_checker.check_api_connectivity.return_value = asyncio.Future()
            mock_checker.check_api_connectivity.return_value.set_result({
                "connected": True,
                "error": None,
                "response_time_ms": 100.0
            })
            mock_checker_class.return_value = mock_checker
            
            async def run_test():
                # Initial validation
                result1 = await self.cache.get_llm_availability("anthropic")
                initial_time = result1["checked_at"]
                
                # Network configuration change simulation
                self.cache.invalidate_network_cache()
                
                # Re-validation after network change
                result2 = await self.cache.get_llm_availability("anthropic")
                updated_time = result2["checked_at"]
                
                # Should have regenerated
                self.assertNotEqual(initial_time, updated_time)
                
                # Cache stats should reflect changes
                stats = self.cache.get_cache_stats()
                self.assertTrue(stats["cache_exists"])
                self.assertIn("network_hash", stats)
            
            asyncio.run(run_test())
    
    def test_cross_service_cache_coordination(self):
        """Test cache coordination across LLM and dependency services."""
        with patch('agentmap.services.config.llm_availability_cache.NetworkConnectivityChecker') as mock_checker_class:
            # Mock connectivity
            mock_checker = Mock()
            mock_checker.check_api_connectivity.return_value = asyncio.Future()
            mock_checker.check_api_connectivity.return_value.set_result({
                "connected": True,
                "error": None,
                "response_time_ms": 100.0
            })
            mock_checker_class.return_value = mock_checker
            
            async def run_test():
                # Validate all LLM providers concurrently
                tasks = [
                    self.cache.get_llm_availability("anthropic"),
                    self.cache.get_llm_availability("openai"),
                    self.cache.get_llm_availability("google")
                ]
                
                results = await asyncio.gather(*tasks)
                
                # All should complete without errors
                for result in results:
                    self.assertIsInstance(result, dict)
                    self.assertIn("enabled", result)
                    self.assertIn("checked_at", result)
                    self.assertIn("validation_results", result)
            
            asyncio.run(run_test())


if __name__ == "__main__":
    unittest.main()
