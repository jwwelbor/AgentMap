"""
Generated Test Template for ExecutionTrackingService.

This test template is generated by the Service Interface Auditor based on
actual service interface analysis to ensure we test real methods, not phantom methods.
Refactored to use pure Mock objects for cleaner, more maintainable tests.
"""

import unittest
from unittest.mock import Mock

from agentmap.services.execution_tracking_service import ExecutionTrackingService
from tests.utils.mock_service_factory import MockServiceFactory


class TestExecutionTrackingService(unittest.TestCase):
    """Unit tests for ExecutionTrackingService with pure Mock dependencies."""

    def setUp(self):
        """Set up test fixtures with pure Mock objects."""
        # Create pure Mock objects - clean and flexible
        self.mock_config_service = Mock()
        self.mock_logging_service = Mock()

        # Configure mock logger to behave like real logger
        self.mock_logger = Mock()
        self.mock_logger.name = "ExecutionTrackingService"
        self.mock_logging_service.get_class_logger.return_value = self.mock_logger

        # Configure default tracking config (can be overridden per test)
        self.mock_config_service.get_tracking_config.return_value = {
            "track_inputs": True,
            "track_outputs": True,
            "enabled": True,
        }

        # Create service instance with mocked dependencies
        self.service = ExecutionTrackingService(
            app_config_service=self.mock_config_service,
            logging_service=self.mock_logging_service,
        )

    def test_service_initialization(self):
        """Test that service initializes correctly with all dependencies."""
        # Verify service is properly configured
        self.assertIsNotNone(self.service)
        self.assertEqual(self.service.logger.name, "ExecutionTrackingService")

        # Verify dependencies were called correctly
        self.mock_logging_service.get_class_logger.assert_called_once_with(self.service)
        self.mock_logger.info.assert_called_with(
            "[ExecutionTrackingService] Initialized"
        )

    def test_create_tracker_method_exists(self):
        """Test that create_tracker method exists and is callable."""
        self.assertTrue(hasattr(self.service, "create_tracker"))
        self.assertTrue(callable(getattr(self.service, "create_tracker")))

    def test_create_tracker_returns_execution_tracker(self):
        """Test that create_tracker returns ExecutionTracker instance."""
        # Configure the mock to return specific tracking config
        self.mock_config_service.get_tracking_config.return_value = {
            "track_inputs": True,
            "track_outputs": True,
            "enabled": True,
        }

        # Call the method
        tracker = self.service.create_tracker()

        # Verify return type and configuration
        from agentmap.models.execution.tracker import ExecutionTracker

        self.assertIsInstance(tracker, ExecutionTracker)
        self.assertTrue(tracker.track_inputs)
        self.assertTrue(tracker.track_outputs)
        self.assertFalse(tracker.minimal_mode)  # enabled=True means minimal_mode=False

        # Verify the config method was called
        self.mock_config_service.get_tracking_config.assert_called_once()

    def test_record_node_start_method_exists(self):
        """Test that record_node_start method exists and is callable."""
        self.assertTrue(hasattr(self.service, "record_node_start"))
        self.assertTrue(callable(getattr(self.service, "record_node_start")))

    def test_record_node_start_updates_tracker(self):
        """Test that record_node_start properly updates tracker."""
        # Configure tracking to capture inputs
        self.mock_config_service.get_tracking_config.return_value = {
            "track_inputs": True,
            "track_outputs": False,
            "enabled": True,
        }

        # Create a tracker with input tracking enabled
        tracker = self.service.create_tracker()

        # Record node start
        test_inputs = {"input": "test_value"}
        self.service.record_node_start(tracker, "test_node", test_inputs)

        # Verify tracking was updated
        self.assertEqual(tracker.node_execution_counts["test_node"], 1)
        self.assertEqual(len(tracker.node_executions), 1)

        node_execution = tracker.node_executions[0]
        self.assertEqual(node_execution.node_name, "test_node")
        self.assertIsNotNone(node_execution.start_time)
        self.assertEqual(node_execution.inputs, test_inputs)  # Now this should work

    def test_record_node_result_method_exists(self):
        """Test that record_node_result method exists and is callable."""
        self.assertTrue(hasattr(self.service, "record_node_result"))
        self.assertTrue(callable(getattr(self.service, "record_node_result")))

    def test_record_node_result_records_success(self):
        """Test that record_node_result properly records successful execution."""
        # Configure tracking for inputs (since we pass them)
        self.mock_config_service.get_tracking_config.return_value = {
            "track_inputs": True,
            "track_outputs": True,
            "enabled": True,
        }

        # Create tracker and start a node
        tracker = self.service.create_tracker()
        self.service.record_node_start(tracker, "test_node", {"input": "test"})

        # Record successful result
        test_result = {"output": "success_result"}
        self.service.record_node_result(tracker, "test_node", True, test_result)

        # Verify result was recorded
        node_execution = tracker.node_executions[0]
        self.assertTrue(node_execution.success)
        self.assertIsNotNone(node_execution.end_time)
        self.assertIsNotNone(node_execution.duration)
        self.assertTrue(tracker.overall_success)  # Should remain True for success

    def test_record_node_result_records_failure(self):
        """Test that record_node_result properly records failed execution."""
        # Configure tracking for inputs (since we pass them)
        self.mock_config_service.get_tracking_config.return_value = {
            "track_inputs": True,
            "track_outputs": False,  # Don't need outputs for failure test
            "enabled": True,
        }

        # Create tracker and start a node
        tracker = self.service.create_tracker()
        self.service.record_node_start(tracker, "test_node", {"input": "test"})

        # Record failed result
        error_message = "Test error occurred"
        self.service.record_node_result(
            tracker, "test_node", False, None, error_message
        )

        # Verify failure was recorded
        node_execution = tracker.node_executions[0]
        self.assertFalse(node_execution.success)
        self.assertEqual(node_execution.error, error_message)
        self.assertFalse(tracker.overall_success)  # Should be False for failure

    def test_complete_execution_method_exists(self):
        """Test that complete_execution method exists and is callable."""
        self.assertTrue(hasattr(self.service, "complete_execution"))
        self.assertTrue(callable(getattr(self.service, "complete_execution")))

    def test_complete_execution_sets_end_time(self):
        """Test that complete_execution sets tracker end time."""
        # Create tracker
        tracker = self.service.create_tracker()
        self.assertIsNone(tracker.end_time)

        # Complete execution
        self.service.complete_execution(tracker)

        # Verify end time was set
        self.assertIsNotNone(tracker.end_time)

    def test_record_subgraph_execution_method_exists(self):
        """Test that record_subgraph_execution method exists and is callable."""
        self.assertTrue(hasattr(self.service, "record_subgraph_execution"))
        self.assertTrue(callable(getattr(self.service, "record_subgraph_execution")))

    def test_to_summary_method_exists(self):
        """Test that to_summary method exists and is callable."""
        self.assertTrue(hasattr(self.service, "to_summary"))
        self.assertTrue(callable(getattr(self.service, "to_summary")))

    def test_to_summary_creates_execution_summary(self):
        """Test that to_summary creates proper ExecutionSummary."""
        # Configure tracking to capture both inputs and outputs
        self.mock_config_service.get_tracking_config.return_value = {
            "track_inputs": True,
            "track_outputs": True,
            "enabled": True,
        }

        # Create tracker with some execution data
        tracker = self.service.create_tracker()
        self.service.record_node_start(tracker, "test_node", {"input": "test"})
        self.service.record_node_result(
            tracker, "test_node", True, {"output": "result"}
        )
        self.service.complete_execution(tracker)

        # Generate summary
        summary = self.service.to_summary(tracker, "test_graph")

        # Verify summary structure
        from agentmap.models.execution.summary import ExecutionSummary

        self.assertIsInstance(summary, ExecutionSummary)
        self.assertEqual(summary.graph_name, "test_graph")
        self.assertEqual(len(summary.node_executions), 1)
        self.assertTrue(summary.graph_success)
        self.assertEqual(summary.status, "completed")

    def test_tracking_disabled_does_not_store_inputs_outputs(self):
        """Test that when tracking is disabled, inputs and outputs are not stored."""
        # Configure tracking as disabled
        self.mock_config_service.get_tracking_config.return_value = {
            "track_inputs": False,
            "track_outputs": False,
            "enabled": True,
        }

        # Create tracker and record execution
        tracker = self.service.create_tracker()
        test_inputs = {"input": "test_value"}
        test_outputs = {"output": "test_result"}

        self.service.record_node_start(tracker, "test_node", test_inputs)
        self.service.record_node_result(tracker, "test_node", True, test_outputs)

        # Verify inputs and outputs were not stored
        node_execution = tracker.node_executions[0]
        self.assertEqual(node_execution.node_name, "test_node")
        self.assertIsNone(
            node_execution.inputs
        )  # Should be None when tracking disabled
        self.assertIsNone(
            node_execution.output
        )  # Should be None when tracking disabled
        self.assertTrue(node_execution.success)  # Success should still be tracked

    def test_create_tracker_with_minimal_mode(self):
        """Test create_tracker with minimal mode configuration."""
        # Configure tracking with minimal mode (enabled=False)
        self.mock_config_service.get_tracking_config.return_value = {
            "track_inputs": False,
            "track_outputs": True,
            "enabled": False,  # This makes minimal_mode = True
        }

        # Reset mock to count calls in this test
        self.mock_config_service.reset_mock()

        # Call the method
        tracker = self.service.create_tracker()

        # Verify return type and configuration
        from agentmap.models.execution.tracker import ExecutionTracker

        self.assertIsInstance(tracker, ExecutionTracker)
        self.assertFalse(tracker.track_inputs)
        self.assertFalse(tracker.track_outputs)
        self.assertTrue(tracker.minimal_mode)  # enabled=False means minimal_mode=True

        # Verify the config method was called
        self.mock_config_service.get_tracking_config.assert_called_once()

    def test_record_node_start_without_input_tracking(self):
        """Test record_node_start with input tracking disabled."""
        # Configure tracking to disable inputs for this test
        self.mock_config_service.get_tracking_config.return_value = {
            "track_inputs": False,  # Disabled for this test
            "track_outputs": True,
            "enabled": True,
        }

        tracker = self.service.create_tracker()
        test_inputs = {"input": "test_value"}

        # Call the method
        self.service.record_node_start(tracker, "test_node", test_inputs)

        # Verify inputs were NOT stored
        node_execution = tracker.node_executions[0]
        self.assertEqual(node_execution.node_name, "test_node")
        self.assertIsNone(node_execution.inputs)  # NOT stored because tracking disabled
        self.assertIsNotNone(node_execution.start_time)

    def test_method_call_verification(self):
        """Test that we can verify method calls on mocks."""
        # Reset call count to test subsequent calls
        self.mock_config_service.reset_mock()

        # Create a tracker
        tracker = self.service.create_tracker()

        # Verify config was called during tracker creation
        self.mock_config_service.get_tracking_config.assert_called_once()

        # Reset call count to test subsequent calls
        self.mock_config_service.reset_mock()

        # Create another tracker
        tracker2 = self.service.create_tracker()

        # Verify config was called again
        self.mock_config_service.get_tracking_config.assert_called_once()


if __name__ == "__main__":
    unittest.main()
