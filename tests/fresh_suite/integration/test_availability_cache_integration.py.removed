"""
Comprehensive integration test suite for availability cache coordination.

Tests cross-service cache coordination, service lifecycle management,
and end-to-end availability checking scenarios across multiple services.

Based on critical issues identified in StorageConfigService availability cache review.
"""
import asyncio
import json
import tempfile
import threading
import time
import unittest
from pathlib import Path
from unittest.mock import patch, MagicMock, Mock, AsyncMock
from datetime import datetime, timezone

from agentmap.services.config.availability_cache import (
    AvailabilityCacheManager,
    ThreadSafeFileCache,
    ValidationStrategy
)
from agentmap.services.config.dependency_availability_cache import (
    DependencyAvailabilityCache,
    DependencyValidationStrategy,
    EnvironmentTracker
)
from agentmap.services.config.llm_availability_cache import (
    LLMAvailabilityCache,
    LLMProviderValidationStrategy
)
from tests.utils.mock_service_factory import MockServiceFactory


class MockStorageValidationStrategy(ValidationStrategy):
    """Mock storage validation strategy for integration testing."""
    
    def __init__(self, storage_type: str, validation_result: Dict[str, Any] = None):
        self.storage_type = storage_type
        self.validation_result = validation_result or {
            "enabled": True,
            "validation_passed": True,
            "last_error": None,
            "checked_at": datetime.now(timezone.utc).isoformat(),
            "warnings": []
        }
        self.call_count = 0
    
    async def validate(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """Mock storage validation."""
        self.call_count += 1
        result = self.validation_result.copy()
        result["checked_at"] = datetime.now(timezone.utc).isoformat()
        result["call_count"] = self.call_count
        return result
    
    def get_cache_key(self, config: Dict[str, Any]) -> str:
        """Generate cache key for storage validation."""
        import hashlib
        content = f"{self.storage_type}:{json.dumps(config, sort_keys=True)}"
        return hashlib.sha256(content.encode()).hexdigest()[:16]


class TestCrossServiceCacheCoordination(unittest.TestCase):
    """Test cache coordination across multiple service types."""
    
    def setUp(self):
        """Set up test fixtures."""
        self.temp_dir = tempfile.mkdtemp()
        
        # Create separate cache files for each service type
        self.storage_cache_file = Path(self.temp_dir) / "storage_cache.json"
        self.dependency_cache_file = Path(self.temp_dir) / "dependency_cache.json"
        self.llm_cache_file = Path(self.temp_dir) / "llm_cache.json"
        
        # Initialize cache services
        self.storage_cache = AvailabilityCacheManager(
            ThreadSafeFileCache(self.storage_cache_file)
        )
        self.dependency_cache = DependencyAvailabilityCache(str(self.dependency_cache_file))
        self.llm_cache = LLMAvailabilityCache(str(self.llm_cache_file))
        
        # Register test strategies
        self._setup_storage_strategies()
        self._setup_dependency_strategies()
        self._setup_llm_strategies()
    
    def tearDown(self):
        """Clean up test fixtures."""
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def _setup_storage_strategies(self):
        """Set up storage validation strategies."""
        csv_strategy = MockStorageValidationStrategy("csv", {
            "enabled": True,
            "validation_passed": True,
            "last_error": None,
            "warnings": []
        })
        vector_strategy = MockStorageValidationStrategy("vector", {
            "enabled": False,
            "validation_passed": False,
            "last_error": "Vector store not configured",
            "warnings": []
        })
        
        self.storage_cache.register_validator("csv", csv_strategy)
        self.storage_cache.register_validator("vector", vector_strategy)
    
    def _setup_dependency_strategies(self):
        """Set up dependency validation strategies."""
        # Register dependency groups with built-in modules
        self.dependency_cache.register_dependency_group("storage_deps", ["json", "os", "sys"])
        self.dependency_cache.register_dependency_group("llm_deps", ["time", "datetime"])
        self.dependency_cache.register_dependency_group("vector_deps", ["nonexistent_vector_lib"])
    
    def _setup_llm_strategies(self):
        """Set up LLM validation strategies."""
        self.llm_cache.register_llm_provider("anthropic", {
            "api_key": "test_anthropic_key",
            "base_url": "https://api.anthropic.com"
        })
        self.llm_cache.register_llm_provider("openai", {
            "api_key": "test_openai_key",
            "base_url": "https://api.openai.com"
        })
    
    @patch('agentmap.services.config.llm_availability_cache.NetworkConnectivityChecker')
    def test_comprehensive_service_availability_check(self, mock_checker_class):
        """Test comprehensive availability check across all service types."""
        # Mock LLM connectivity
        mock_checker = Mock()
        mock_checker.check_api_connectivity.return_value = asyncio.Future()
        mock_checker.check_api_connectivity.return_value.set_result({
            "connected": True,
            "error": None,
            "response_time_ms": 100.0
        })
        mock_checker_class.return_value = mock_checker
        
        async def run_test():
            config = {"test": "comprehensive_config"}
            
            # Check all service types concurrently
            storage_tasks = [
                self.storage_cache.get_or_generate_availability("csv", config),
                self.storage_cache.get_or_generate_availability("vector", config)
            ]
            
            dependency_tasks = [
                self.dependency_cache.get_dependency_availability("storage_deps", config),
                self.dependency_cache.get_dependency_availability("llm_deps", config),
                self.dependency_cache.get_dependency_availability("vector_deps", config)
            ]
            
            llm_tasks = [
                self.llm_cache.get_llm_availability("anthropic", config),
                self.llm_cache.get_llm_availability("openai", config)
            ]
            
            # Execute all checks concurrently
            all_results = await asyncio.gather(
                *storage_tasks,
                *dependency_tasks,
                *llm_tasks,
                return_exceptions=True
            )
            
            # Verify all completed without exceptions
            for i, result in enumerate(all_results):
                self.assertIsInstance(result, dict, f"Result {i} should be dict, got {type(result)}")
                self.assertIn("enabled", result, f"Result {i} missing 'enabled' field")
                self.assertIn("checked_at", result, f"Result {i} missing 'checked_at' field")
            
            # Verify specific results
            csv_result, vector_result = all_results[0:2]
            storage_deps_result, llm_deps_result, vector_deps_result = all_results[2:5]
            anthropic_result, openai_result = all_results[5:7]
            
            # Storage results
            self.assertTrue(csv_result["enabled"])
            self.assertFalse(vector_result["enabled"])
            
            # Dependency results
            self.assertTrue(storage_deps_result["enabled"])  # Built-in modules
            self.assertTrue(llm_deps_result["enabled"])  # Built-in modules
            self.assertFalse(vector_deps_result["enabled"])  # Non-existent module
            
            # LLM results (mocked as available)
            self.assertTrue(anthropic_result["enabled"])
            self.assertTrue(openai_result["enabled"])
        
        asyncio.run(run_test())
    
    def test_cache_file_isolation(self):
        """Test that different services maintain isolated cache files."""
        async def run_test():
            config = {"test": "isolation"}
            
            # Generate caches for different services
            await self.storage_cache.get_or_generate_availability("csv", config)
            await self.dependency_cache.get_dependency_availability("storage_deps", config)
        
        asyncio.run(run_test())
        
        # Verify separate cache files exist
        self.assertTrue(self.storage_cache_file.exists())
        self.assertTrue(self.dependency_cache_file.exists())
        
        # Verify cache file contents are different
        with open(self.storage_cache_file, 'r') as f:
            storage_cache_data = json.load(f)
        
        with open(self.dependency_cache_file, 'r') as f:
            dependency_cache_data = json.load(f)
        
        self.assertNotEqual(storage_cache_data, dependency_cache_data)
        
        # Verify each cache contains appropriate data
        self.assertIn("availability", storage_cache_data)
        self.assertIn("csv", storage_cache_data["availability"])
        
        self.assertIn("availability", dependency_cache_data)
        self.assertIn("dependency.storage_deps", dependency_cache_data["availability"])
    
    def test_concurrent_cross_service_validation(self):
        """Test concurrent validation across multiple services is thread-safe."""
        with patch('agentmap.services.config.llm_availability_cache.NetworkConnectivityChecker') as mock_checker_class:
            # Mock LLM connectivity
            mock_checker = Mock()
            mock_checker.check_api_connectivity.return_value = asyncio.Future()
            mock_checker.check_api_connectivity.return_value.set_result({
                "connected": True,
                "error": None,
                "response_time_ms": 100.0
            })
            mock_checker_class.return_value = mock_checker
            
            results = []
            errors = []
            
            def worker_thread(thread_id: int):
                """Worker thread that validates across all services."""
                try:
                    async def validate_all():
                        config = {"thread_id": thread_id}
                        
                        # Validate across all service types
                        storage_result = await self.storage_cache.get_or_generate_availability("csv", config)
                        dependency_result = await self.dependency_cache.get_dependency_availability("storage_deps", config)
                        llm_result = await self.llm_cache.get_llm_availability("anthropic", config)
                        
                        return {
                            "storage": storage_result["enabled"],
                            "dependency": dependency_result["enabled"],
                            "llm": llm_result["enabled"]
                        }
                    
                    result = asyncio.run(validate_all())
                    results.append((thread_id, result))
                    
                except Exception as e:
                    errors.append((thread_id, str(e)))
            
            # Start multiple concurrent threads
            threads = []
            for i in range(5):
                thread = threading.Thread(target=worker_thread, args=(i,))
                threads.append(thread)
                thread.start()
            
            # Wait for all threads to complete
            for thread in threads:
                thread.join()
            
            # Verify no errors and all validations succeeded
            self.assertEqual(len(errors), 0, f"Thread safety errors: {errors}")
            self.assertEqual(len(results), 5)
            
            for thread_id, result in results:
                self.assertTrue(result["storage"], f"Thread {thread_id} storage validation failed")
                self.assertTrue(result["dependency"], f"Thread {thread_id} dependency validation failed")
                self.assertTrue(result["llm"], f"Thread {thread_id} LLM validation failed")
    
    def test_cache_invalidation_coordination(self):
        """Test coordinated cache invalidation across services."""
        with patch('agentmap.services.config.llm_availability_cache.NetworkConnectivityChecker') as mock_checker_class:
            # Mock LLM connectivity
            mock_checker = Mock()
            mock_checker.check_api_connectivity.return_value = asyncio.Future()
            mock_checker.check_api_connectivity.return_value.set_result({
                "connected": True,
                "error": None,
                "response_time_ms": 100.0
            })
            mock_checker_class.return_value = mock_checker
            
            async def run_test():
                config = {"test": "invalidation"}
                
                # Generate initial caches
                storage_result1 = await self.storage_cache.get_or_generate_availability("csv", config)
                dependency_result1 = await self.dependency_cache.get_dependency_availability("storage_deps", config)
                llm_result1 = await self.llm_cache.get_llm_availability("anthropic", config)
                
                initial_times = {
                    "storage": storage_result1["checked_at"],
                    "dependency": dependency_result1["checked_at"],
                    "llm": llm_result1["checked_at"]
                }
                
                # Simulate coordinated cache invalidation
                self.storage_cache.clear_cache("csv")
                self.dependency_cache.clear_dependency_cache("storage_deps")
                self.llm_cache.clear_llm_cache("anthropic")
                
                # Re-validate after invalidation
                storage_result2 = await self.storage_cache.get_or_generate_availability("csv", config)
                dependency_result2 = await self.dependency_cache.get_dependency_availability("storage_deps", config)
                llm_result2 = await self.llm_cache.get_llm_availability("anthropic", config)
                
                updated_times = {
                    "storage": storage_result2["checked_at"],
                    "dependency": dependency_result2["checked_at"],
                    "llm": llm_result2["checked_at"]
                }
                
                # All caches should have been regenerated
                for service_type in ["storage", "dependency", "llm"]:
                    self.assertNotEqual(
                        initial_times[service_type],
                        updated_times[service_type],
                        f"{service_type} cache was not regenerated"
                    )
            
            asyncio.run(run_test())
    
    def test_performance_across_services(self):
        """Test performance characteristics across multiple services."""
        with patch('agentmap.services.config.llm_availability_cache.NetworkConnectivityChecker') as mock_checker_class:
            # Mock fast LLM connectivity
            mock_checker = Mock()
            mock_checker.check_api_connectivity.return_value = asyncio.Future()
            mock_checker.check_api_connectivity.return_value.set_result({
                "connected": True,
                "error": None,
                "response_time_ms": 50.0
            })
            mock_checker_class.return_value = mock_checker
            
            async def run_test():
                config = {"test": "performance"}
                
                # Generate caches first
                await self.storage_cache.get_or_generate_availability("csv", config)
                await self.dependency_cache.get_dependency_availability("storage_deps", config)
                await self.llm_cache.get_llm_availability("anthropic", config)
                
                # Measure cross-service cache hit performance
                all_hit_times = []
                
                for _ in range(20):
                    start_time = time.perf_counter()
                    
                    # Concurrent cache hits across all services
                    results = await asyncio.gather(
                        self.storage_cache.get_or_generate_availability("csv", config),
                        self.dependency_cache.get_dependency_availability("storage_deps", config),
                        self.llm_cache.get_llm_availability("anthropic", config)
                    )
                    
                    end_time = time.perf_counter()
                    all_hit_times.append((end_time - start_time) * 1000)  # ms
                    
                    # Verify all hits succeeded
                    for result in results:
                        self.assertIn("enabled", result)
                
                avg_hit_time = sum(all_hit_times) / len(all_hit_times)
                max_hit_time = max(all_hit_times)
                
                # Performance targets (should be fast for cache hits)
                self.assertLess(avg_hit_time, 5.0, f"Avg cross-service hit {avg_hit_time:.3f}ms exceeds 5ms target")
                self.assertLess(max_hit_time, 20.0, f"Max cross-service hit {max_hit_time:.3f}ms exceeds 20ms threshold")
            
            asyncio.run(run_test())


class TestServiceLifecycleManagement(unittest.TestCase):
    """Test availability cache throughout service lifecycle."""
    
    def setUp(self):
        """Set up test fixtures."""
        self.temp_dir = tempfile.mkdtemp()
        self.cache_file = Path(self.temp_dir) / "lifecycle_cache.json"
        
        # Create unified cache manager for lifecycle testing
        self.cache_manager = AvailabilityCacheManager(
            ThreadSafeFileCache(self.cache_file)
        )
        
        # Register strategies for different service types
        self._register_lifecycle_strategies()
    
    def tearDown(self):
        """Clean up test fixtures."""
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def _register_lifecycle_strategies(self):
        """Register validation strategies for lifecycle testing."""
        # Storage strategies
        csv_strategy = MockStorageValidationStrategy("csv")
        json_strategy = MockStorageValidationStrategy("json")
        vector_strategy = MockStorageValidationStrategy("vector", {
            "enabled": False,
            "validation_passed": False,
            "last_error": "Vector dependencies missing",
            "warnings": ["Consider installing chromadb"]
        })
        
        self.cache_manager.register_validator("csv", csv_strategy)
        self.cache_manager.register_validator("json", json_strategy)
        self.cache_manager.register_validator("vector", vector_strategy)
    
    def test_service_startup_sequence(self):
        """Test cache behavior during service startup sequence."""
        async def run_test():
            startup_config = {"phase": "startup"}
            
            # Phase 1: Initial validation (cache miss)
            startup_results = await asyncio.gather(
                self.cache_manager.get_or_generate_availability("csv", startup_config),
                self.cache_manager.get_or_generate_availability("json", startup_config),
                self.cache_manager.get_or_generate_availability("vector", startup_config)
            )
            
            # Verify initial validation results
            csv_result, json_result, vector_result = startup_results
            
            self.assertTrue(csv_result["enabled"])
            self.assertTrue(json_result["enabled"])
            self.assertFalse(vector_result["enabled"])
            
            # Phase 2: Rapid subsequent checks (cache hits)
            quick_check_times = []
            for _ in range(10):
                start_time = time.perf_counter()
                quick_results = await asyncio.gather(
                    self.cache_manager.get_or_generate_availability("csv", startup_config),
                    self.cache_manager.get_or_generate_availability("json", startup_config)
                )
                end_time = time.perf_counter()
                
                quick_check_times.append((end_time - start_time) * 1000)
                
                # Results should be from cache
                for result in quick_results:
                    self.assertTrue(result["enabled"])
            
            # Quick checks should be fast (cache hits)
            avg_quick_time = sum(quick_check_times) / len(quick_check_times)
            self.assertLess(avg_quick_time, 2.0, f"Quick checks averaged {avg_quick_time:.3f}ms")
        
        asyncio.run(run_test())
    
    def test_service_reconfiguration_cycle(self):
        """Test cache behavior during service reconfiguration."""
        async def run_test():
            # Initial configuration
            initial_config = {"storage_type": "csv", "version": "1.0"}
            result1 = await self.cache_manager.get_or_generate_availability("csv", initial_config)
            initial_time = result1["checked_at"]
            
            # Configuration change
            updated_config = {"storage_type": "csv", "version": "2.0", "features": ["advanced"]}
            result2 = await self.cache_manager.get_or_generate_availability("csv", updated_config)
            updated_time = result2["checked_at"]
            
            # Should regenerate due to config change
            self.assertNotEqual(initial_time, updated_time)
            
            # Subsequent calls with same config should hit cache
            result3 = await self.cache_manager.get_or_generate_availability("csv", updated_config)
            cached_time = result3["checked_at"]
            
            self.assertEqual(updated_time, cached_time)
        
        asyncio.run(run_test())
    
    def test_service_shutdown_cleanup(self):
        """Test proper cleanup during service shutdown."""
        async def run_test():
            config = {"phase": "shutdown"}
            
            # Generate some cache data
            await self.cache_manager.get_or_generate_availability("csv", config)
            await self.cache_manager.get_or_generate_availability("json", config)
            
            # Verify cache file exists
            self.assertTrue(self.cache_file.exists())
            
            # Simulate graceful shutdown
            self.cache_manager.clear_cache()
            
            # Cache file should be cleaned up
            self.assertFalse(self.cache_file.exists())
        
        asyncio.run(run_test())
    
    def test_service_crash_recovery(self):
        """Test cache recovery after service crash simulation."""
        async def run_test():
            config = {"phase": "recovery"}
            
            # Generate initial cache
            result1 = await self.cache_manager.get_or_generate_availability("csv", config)
            self.assertTrue(result1["enabled"])
            
            # Simulate cache corruption (incomplete write)
            with open(self.cache_file, 'w') as f:
                f.write('{"incomplete": json')
            
            # Service should recover gracefully
            result2 = await self.cache_manager.get_or_generate_availability("csv", config)
            self.assertTrue(result2["enabled"])
            
            # Cache should be regenerated
            self.assertNotEqual(result1["checked_at"], result2["checked_at"])
        
        asyncio.run(run_test())


class TestEdgeCaseValidation(unittest.TestCase):
    """Test edge cases identified in architectural review."""
    
    def setUp(self):
        """Set up test fixtures."""
        self.temp_dir = tempfile.mkdtemp()
        self.cache_file = Path(self.temp_dir) / "edge_case_cache.json"
        self.cache = ThreadSafeFileCache(self.cache_file)
        self.test_config = {"test": "edge_cases"}
    
    def tearDown(self):
        """Clean up test fixtures."""
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_clock_skew_handling(self):
        """Test handling of clock skew scenarios."""
        # Create cache with future timestamp (simulating clock skew)
        future_time = time.time() + 3600  # 1 hour in future
        cache_data = {
            "cache_version": "1.1",
            "config_hash": self.cache._get_full_config_hash(self.test_config),
            "config_mtime": future_time,
            "generated_at": datetime.now(timezone.utc).isoformat(),
            "availability": {"test": {"enabled": True}}
        }
        
        self.cache.save_cache(cache_data)
        
        # Create config file with current timestamp
        config_file = Path(self.temp_dir) / "config.yaml"
        config_file.touch()
        
        # Validation should handle clock skew gracefully (within tolerance)
        result = self.cache.validate_cache(self.test_config, config_file)
        
        # Should not fail due to reasonable time differences
        # The 5-second tolerance should handle most clock skew scenarios
        if abs(future_time - config_file.stat().st_mtime) <= 5.0:
            self.assertTrue(result.file_mtime_match)
        else:
            self.assertFalse(result.file_mtime_match)
    
    def test_hash_collision_avoidance(self):
        """Test that full SHA-256 hashes avoid collisions."""
        # Create similar but different configs
        config1 = {"storage": "csv", "path": "/data1"}
        config2 = {"storage": "csv", "path": "/data2"}
        
        hash1 = self.cache._get_full_config_hash(config1)
        hash2 = self.cache._get_full_config_hash(config2)
        
        # Hashes should be different (full SHA-256 reduces collision risk)
        self.assertNotEqual(hash1, hash2)
        
        # Both should be full 64-character SHA-256 hashes
        self.assertEqual(len(hash1), 64)
        self.assertEqual(len(hash2), 64)
    
    def test_file_system_race_conditions(self):
        """Test handling of file system race conditions."""
        import tempfile
        
        # Create a scenario where file modification happens during validation
        config_file = Path(self.temp_dir) / "racing_config.yaml"
        config_file.write_text("initial content")
        
        original_mtime = config_file.stat().st_mtime
        
        # Create cache with original mtime
        cache_data = {
            "cache_version": "1.1",
            "config_hash": self.cache._get_full_config_hash(self.test_config),
            "config_mtime": original_mtime,
            "generated_at": datetime.now(timezone.utc).isoformat()
        }
        
        self.cache.save_cache(cache_data)
        
        # Simulate file modification during validation
        time.sleep(0.01)  # Ensure different mtime
        config_file.write_text("modified content")
        
        # Validation should detect the file change
        result = self.cache.validate_cache(self.test_config, config_file)
        
        # Should detect file modification
        if abs(config_file.stat().st_mtime - original_mtime) > 5.0:
            self.assertFalse(result.file_mtime_match)
            self.assertFalse(result.is_valid)
    
    def test_version_compatibility_edge_cases(self):
        """Test version compatibility edge cases."""
        # Test exact version match
        cache_data = {
            "cache_version": "1.1",
            "config_hash": self.cache._get_full_config_hash(self.test_config),
            "generated_at": datetime.now(timezone.utc).isoformat()
        }
        
        self.cache.save_cache(cache_data)
        result = self.cache.validate_cache(self.test_config)
        self.assertTrue(result.version_compatible)
        
        # Test version mismatch
        cache_data["cache_version"] = "2.0"
        self.cache.save_cache(cache_data)
        result = self.cache.validate_cache(self.test_config)
        self.assertFalse(result.version_compatible)
        
        # Test missing version (should fail)
        cache_data.pop("cache_version", None)
        self.cache.save_cache(cache_data)
        result = self.cache.validate_cache(self.test_config)
        self.assertFalse(result.version_compatible)
    
    def test_memory_pressure_scenarios(self):
        """Test behavior under memory pressure scenarios."""
        import gc
        
        # Generate large cache data to simulate memory pressure
        large_cache_data = {
            "cache_version": "1.1",
            "config_hash": self.cache._get_full_config_hash(self.test_config),
            "generated_at": datetime.now(timezone.utc).isoformat(),
            "availability": {}
        }
        
        # Add large amount of data
        for i in range(1000):
            large_cache_data["availability"][f"storage_{i}"] = {
                "enabled": i % 2 == 0,
                "data": ["item"] * 100  # Bulk data
            }
        
        # Save and load large cache
        success = self.cache.save_cache(large_cache_data)
        self.assertTrue(success)
        
        loaded_data = self.cache.load_cache()
        self.assertIsNotNone(loaded_data)
        
        # Cleanup should work properly
        self.cache._cleanup_resources()
        
        # Force garbage collection
        gc.collect()
        
        # Should still be able to operate after cleanup
        small_cache_data = {
            "cache_version": "1.1",
            "config_hash": self.cache._get_full_config_hash(self.test_config),
            "generated_at": datetime.now(timezone.utc).isoformat(),
            "availability": {"test": {"enabled": True}}
        }
        
        success = self.cache.save_cache(small_cache_data)
        self.assertTrue(success)


if __name__ == "__main__":
    unittest.main()
